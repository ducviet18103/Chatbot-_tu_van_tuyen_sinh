import time
import os
import pandas as pd
import joblib
import streamlit as st
from streamlit.runtime.scriptrunner import add_script_run_ctx
import google.generativeai as genai
from components.openai_component.gemini_chat import GeminiChat
from components.search_info.domain_qdrant import QdrantSetup
from dotenv import load_dotenv
from datetime import datetime
load_dotenv()
GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')
genai.configure(api_key=GOOGLE_API_KEY)

# Disable the default Streamlit rerun animation
st.set_page_config(
    page_title="HUST",
    page_icon="üëã",
    initial_sidebar_state="expanded"
)

hide_streamlit_style = """
<style>
    #root > div:nth-child(1) > div > div > div > div > section > div {opacity: 100% !important}
    .stDeployButton {display:none;}
    .loader {display: none;}
    .stMarkdown {opacity: 100% !important}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# Initialize QdrantSetup once and store in session state
@st.cache_resource
def init_qdrant():
    return QdrantSetup()

if 'setup' not in st.session_state:
    st.session_state.setup = init_qdrant()

# Initialize other components
gemini_chat = GeminiChat()
def generate_chat_id():
    # L·∫•y th·ªùi gian hi·ªán t·∫°i
    current_time = datetime.now()
    # ƒê·ªãnh d·∫°ng th·ªùi gian th√†nh chu·ªói ng√†y, th√°ng, nƒÉm, gi·ªù, ph√∫t, gi√¢y
    chat_id = current_time.strftime('%Y%m%d_%H%M%S')  # V√≠ d·ª•: "20241014_123045"
    return chat_id

# S·ª≠ d·ª•ng h√†m
new_chat_id = generate_chat_id()
# new_chat_id = f'{time.time()}'
# st.write(new_chat_id)
MODEL_ROLE = 'ai'
AI_AVATAR_ICON = '‚ú®'

# Create system prompt
SYSTEM_PROMPT = """T√¥i l√† Admin c·ªßa tr∆∞·ªùng ƒê·∫°i h·ªçc B√°ch khoa H√† N·ªôi (HUST).
Nhi·ªám v·ª• c·ªßa t√¥i l√† cung c·∫•p th√¥ng tin ch√≠nh x√°c v√† h·ªØu √≠ch v·ªÅ tuy·ªÉn sinh, c√°c ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o, c≈©ng nh∆∞ cu·ªôc s·ªëng sinh vi√™n t·∫°i HUST.
T√¥i lu√¥n gi·ªØ th√°i ƒë·ªô chuy√™n nghi·ªáp, th√¢n thi·ªán v√† cung c·∫•p c√¢u tr·∫£ l·ªùi chi ti·∫øt d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p.
N·∫øu c√≥ th√¥ng tin t√¥i kh√¥ng ch·∫Øc ch·∫Øn, t√¥i s·∫Ω th·∫≥ng th·∫Øn th·ª´a nh·∫≠n v√† g·ª£i √Ω n∆°i b·∫°n c√≥ th·ªÉ t√¨m th·∫•y th√¥ng tin ch√≠nh x√°c h∆°n.
T√¥i s·∫Ω tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát tr·ª´ khi b·∫°n y√™u c·∫ßu s·ª≠ d·ª•ng ng√¥n ng·ªØ kh√°c.
H√£y cho t√¥i bi·∫øt b·∫°n c·∫ßn h·ªó tr·ª£ g√¨ nh√©! """

# Create a data/ folder if it doesn't exist
os.makedirs('data/', exist_ok=True)

# Load past chats
@st.cache_data
def load_past_chats():
    try:
        return joblib.load('data/past_chats_list')
    except:
        return {}

past_chats = load_past_chats()

# Sidebar for chat history
with st.sidebar:
    st.write('# L·ªãch s·ª≠')
    if st.session_state.get('chat_id') is None:
        st.session_state.chat_id = st.selectbox(
            label='Ch·ªçn l·ªãch s·ª≠ chat',
            options=[new_chat_id] + list(past_chats.keys()),
            format_func=lambda x: past_chats.get(x, 'ƒêo·∫°n chat m·ªõi'),
            placeholder='_',
        )
    else:
        st.session_state.chat_id = st.selectbox(
            label='Ch·ªçn l·ªãch s·ª≠ chat',
            options=[new_chat_id, st.session_state.chat_id] + list(past_chats.keys()),
            index=1,
            format_func=lambda x: past_chats.get(x, 'ƒêo·∫°n chat m·ªõi' if x != st.session_state.chat_id else st.session_state.chat_title),
            placeholder='_',
        )
    st.session_state.chat_title = f'ƒêo·∫°n chat-{st.session_state.chat_id}'
    
    #Upload file to domain knowledge
    uploaded_file = st.file_uploader("T·∫£i t√†i li·ªáu l√™n", type=['xlsx', 'csv' ,'txt'])
    if uploaded_file is not None:
        file_path = f"data_domain/{uploaded_file.name}"
         # Check if the file already exists
        if not os.path.exists(file_path):
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
        docs_total = []
        if uploaded_file.name.endswith('.xlsx'):
            df = pd.read_excel(file_path)
            docs = st.session_state.setup.insert_dataframe(df)
            docs_total += docs
            # st.session_state.setup.insert_documents_if_exist(docs, collection_name='domain_chatbot')
            st.write("File loaded successfully as an Excel file:")
        elif uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(file_path)
            docs = st.session_state.setup.insert_dataframe(df)
            docs_total += docs
            # st.session_state.setup.insert_documents_if_exist(docs, collection_name='domain_chatbot')
            st.write("File loaded successfully as a CSV file:")
        elif uploaded_file.name.endswith('.txt'):
            documents = st.session_state.setup.insert_text_file(uploaded_file, uploaded_file.name)
            docs = st.session_state.setup.chunk_documents(documents)
            docs_total += docs
            st.write("File loaded successfully as a Text file:")
        else:
            st.error("Unsupported file format.")
            
        if st.button("Insert documents"):
            if docs_total:
                st.session_state.setup.insert_documents_if_exist(docs_total, collection_name='domain_chatbot')
                st.success("Insert file successfully.")
            else:
                st.error("No documents to insert.")
        
st.write('# Chatbot t∆∞ v·∫•n tuy·ªÉn sinh :violet[HUST] :sunglasses:')

# Initialize or load chat history
@st.cache_data
def load_chat_history():
    try:
        messages = joblib.load(f'data/{st.session_state.chat_id}-st_messages')
        gemini_history = joblib.load(f'data/{st.session_state.chat_id}-gemini_messages')
        return messages, gemini_history
    except:
        return [], []

if 'messages' not in st.session_state:
    st.session_state.messages, st.session_state.gemini_history = load_chat_history()

# Initialize Gemini model with system prompt
@st.cache_resource
def initialize_chat():
    model = genai.GenerativeModel(model_name="gemini-1.5-pro")
    chat = model.start_chat(history=[])
    combined_prompt = f"{gemini_chat.generate_message_obj()}\n\n{SYSTEM_PROMPT}"
    chat.send_message(combined_prompt, stream=False)
    return chat

if 'chat' not in st.session_state:
    st.session_state.chat = initialize_chat()

# Create a container for chat messages
chat_container = st.container()

# Display chat history
with chat_container:
    for message in st.session_state.messages:
        with st.chat_message(name=message['role'], avatar=message.get('avatar')):
            st.markdown(message['content'])

# Function to process user input and generate response
def process_message(prompt, message_placeholder):
    try:
        # Use the cached QdrantSetup instance
        all_results, all_documents = st.session_state.setup.perform_search(prompt)
        reranked_results = st.session_state.setup.reciprocal_rank_fusion(all_results)
        all_documents_sorted = [all_documents[i] for i in reranked_results.keys()]
        print("All documents sorted:", all_documents_sorted)

        prompt_with_context = f"""
        C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {prompt}
        
        T√†i li·ªáu li√™n quan: {all_documents_sorted}
        
        T√†i li·ªáu li√™n quan c√≥ th·ªÉ l√† b·ªô c√¢u h·ªèi v√† tr·∫£ l·ªùi t√¥i ƒë√£ chu·∫©n b·ªã tr∆∞·ªõc ƒë√≥. B·∫°n h√£y ch·ªçn ra nh·ªØng th√¥ng tin ch√≠nh x√°c v√† c·∫ßn thi·∫øt nh·∫•t ƒë·ªÉ c√≥ th·ªÉ tr·∫£ l·ªùi t·ªët nh·∫•t.
        N·∫øu t√†i li·ªáu li√™n quan c√≥ nhi·ªÅu nƒÉm kh√°c nhau, nh·ªõ l∆∞u √Ω ƒë·ªÉ tr·∫£ l·ªùi ghi ch√∫ r√µ r√†ng nƒÉm n√†o.
        N·∫øu b·ªô c√¢u h·ªèi kh√¥ng li√™n quan, h√£y tr·∫£ l·ªùi t√¥i kh√¥ng bi·∫øt, kh√¥ng tr·∫£ l·ªùi b·ªãa th√¥ng tin ho·∫∑c c√≥ th·ªÉ g·ª£i √Ω n∆°i b·∫°n c√≥ th·ªÉ t√¨m th√™m th√¥ng tin.       
        H√£y tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát d·ª±a tr√™n ng·ªØ c·∫£nh ƒë∆∞·ª£c cung c·∫•p v√† tu√¢n theo h∆∞·ªõng d·∫´n h·ªá th·ªëng.
        """

        full_response = ''
        response = st.session_state.chat.send_message(prompt_with_context, stream=True)
        text_buffer = ''
        
        for chunk in response:
            chunk_text = chunk.text
            
            # X·ª≠ l√Ω t·ª´ng k√Ω t·ª± thay v√¨ split theo space
            for char in chunk_text:
                text_buffer += char
                
                # Ch·ªâ hi·ªÉn th·ªã khi g·∫∑p d·∫•u c√¢u ho·∫∑c kho·∫£ng tr·∫Øng
                if char in [' ', '.', '!', '?', '\n', ',', ':', ';']:
                    full_response += text_buffer
                    message_placeholder.markdown(full_response + '‚ñå')
                    text_buffer = ''
                    time.sleep(0.05)
        
        # Th√™m ph·∫ßn text c√≤n l·∫°i trong buffer (n·∫øu c√≥)
        if text_buffer:
            full_response += text_buffer
            message_placeholder.markdown(full_response)
        # for chunk in response:
        #     for ch in chunk.text.split(' '):
        #         full_response += ch + ' '
        #         message_placeholder.markdown(full_response + '‚ñå')
        #         time.sleep(0.05)
        
        # message_placeholder.markdown(full_response)
        # print("Full response:", full_response)
        # Save response to session state
        st.session_state.messages.append({
            'role': MODEL_ROLE,
            'content': full_response,
            'avatar': AI_AVATAR_ICON,
        })
        
        st.session_state.gemini_history = st.session_state.chat.history
        
        # Save chat history
        joblib.dump(st.session_state.messages, f'data/{st.session_state.chat_id}-st_messages')
        joblib.dump(st.session_state.gemini_history, f'data/{st.session_state.chat_id}-gemini_messages')
        
    except Exception as e:
        st.error(f"C√≥ l·ªói x·∫£y ra: {str(e)}")
        st.session_state.chat = initialize_chat()

# Handle user input
if prompt := st.chat_input('Nh·∫≠p c√¢u h·ªèi...'):
    # Save chat to history
    if st.session_state.chat_id not in past_chats.keys():
        past_chats[st.session_state.chat_id] = st.session_state.chat_title
        joblib.dump(past_chats, 'data/past_chats_list')

    # Display user message
    with chat_container:
        with st.chat_message('user'):
            st.markdown(prompt)
        st.session_state.messages.append({
            'role': 'user',
            'content': prompt,
        })
        
        # Create a message placeholder for the assistant's response
        with st.chat_message(name=MODEL_ROLE, avatar=AI_AVATAR_ICON):
            message_placeholder = st.empty()
            process_message(prompt, message_placeholder)